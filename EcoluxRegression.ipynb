{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Upload Dataset"
      ],
      "metadata": {
        "id": "sMISnNMasvPM"
      },
      "id": "sMISnNMasvPM"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "nSRayliLXAiK",
        "outputId": "71dde981-a821-4237-da59-a38d82176a2b"
      },
      "id": "nSRayliLXAiK",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0f8c3bb9-43ff-4022-8cf1-ca675fae03ab\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0f8c3bb9-43ff-4022-8cf1-ca675fae03ab\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving allHouses.csv to allHouses.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "house_df = pd.read_csv(io.StringIO(uploaded['allHouses.csv'].decode('utf-8')))\n",
        "print(house_df.columns.to_list())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4upR4XfWzIq",
        "outputId": "466e4dc3-b0d1-4e8d-8dc5-2537e0a78c7f"
      },
      "id": "S4upR4XfWzIq",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['HouseNum', 'TimeSin', 'TimeCos', 'DayNumSin', 'DayNumCos', 'MonthSin', 'MonthCos', 'RealTemp', 'ApparTemp', 'Humid', 'Wmo_0-9', 'Wmo_10-19', 'Wmo_20-29', 'Wmo_30-39', 'Wmo_40-49', 'Wmo_50-59', 'Wmo_60-69', 'Wmo_70-79', 'Wmo_80-89', 'Wmo_90-99', 'YearBuilt__under_1899', 'YearBuilt_1900-1909', 'YearBuilt_1910-1919', 'YearBuilt_1920-1929', 'YearBuilt_1930-1939', 'YearBuilt_1940-1949', 'YearBuilt_1950-1959', 'YearBuilt_1960-1969', 'YearBuilt_1970-1979', 'YearBuilt_1980-1989', 'YearBuilt_1990-1999', 'YearBuilt_2000-2009', 'YearBuilt_2010-2019', 'YearBuilt_2020-2029', 'Type_BUNGALOW', 'Type_COTTAGE', 'Type_DETACHED', 'Type_END OF TERRACE', 'Type_FLAT', 'Type_SEMI-DETACHED', 'Type_MID-TERRACE', 'Type_STUDENT HALLS', 'Type_FACTORY', 'Type_OFFICE', 'Type_UNIVERSITY', 'NumRooms', 'NumOccupants', 'Total', 'AlwaysOn', 'Intermit', 'HVAC']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/allHouses.csv'\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "house_df = pd.read_csv(file_path)\n",
        "print(house_df.columns.to_list())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZy-V-zQyn9Y",
        "outputId": "2c64f233-3d73-45df-ecb9-f1932a2c5033"
      },
      "id": "GZy-V-zQyn9Y",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['HouseNum', 'TimeSin', 'TimeCos', 'DayNumSin', 'DayNumCos', 'MonthSin', 'MonthCos', 'RealTemp', 'ApparTemp', 'Humid', 'Wmo_0-9', 'Wmo_10-19', 'Wmo_20-29', 'Wmo_30-39', 'Wmo_40-49', 'Wmo_50-59', 'Wmo_60-69', 'Wmo_70-79', 'Wmo_80-89', 'Wmo_90-99', 'YearBuilt__under_1899', 'YearBuilt_1900-1909', 'YearBuilt_1910-1919', 'YearBuilt_1920-1929', 'YearBuilt_1930-1939', 'YearBuilt_1940-1949', 'YearBuilt_1950-1959', 'YearBuilt_1960-1969', 'YearBuilt_1970-1979', 'YearBuilt_1980-1989', 'YearBuilt_1990-1999', 'YearBuilt_2000-2009', 'YearBuilt_2010-2019', 'YearBuilt_2020-2029', 'Type_BUNGALOW', 'Type_COTTAGE', 'Type_DETACHED', 'Type_END OF TERRACE', 'Type_FLAT', 'Type_SEMI-DETACHED', 'Type_MID-TERRACE', 'Type_STUDENT HALLS', 'Type_FACTORY', 'Type_OFFICE', 'Type_UNIVERSITY', 'NumRooms', 'NumOccupants', 'Total', 'AlwaysOn', 'Intermit', 'HVAC']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11f4be37-50cb-4884-98d0-5433aff0db10",
      "metadata": {
        "scrolled": true,
        "id": "11f4be37-50cb-4884-98d0-5433aff0db10"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "# Read in the csv\n",
        "houses_dataset = r'C:'\n",
        "house_df = pd.read_csv(houses_dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up model"
      ],
      "metadata": {
        "id": "gSPUk1disgdF"
      },
      "id": "gSPUk1disgdF"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "866fabb2-03e7-4a8b-af53-d7f94a991443",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "866fabb2-03e7-4a8b-af53-d7f94a991443",
        "outputId": "253beaf5-b7d2-4f62-97f9-badf14d30ed8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "house_df---->>>> ['HouseNum', 'TimeSin', 'TimeCos', 'DayNumSin', 'DayNumCos', 'MonthSin', 'MonthCos', 'RealTemp', 'ApparTemp', 'Humid', 'Wmo_0-9', 'Wmo_10-19', 'Wmo_20-29', 'Wmo_30-39', 'Wmo_40-49', 'Wmo_50-59', 'Wmo_60-69', 'Wmo_70-79', 'Wmo_80-89', 'Wmo_90-99', 'YearBuilt__under_1899', 'YearBuilt_1900-1909', 'YearBuilt_1910-1919', 'YearBuilt_1920-1929', 'YearBuilt_1930-1939', 'YearBuilt_1940-1949', 'YearBuilt_1950-1959', 'YearBuilt_1960-1969', 'YearBuilt_1970-1979', 'YearBuilt_1980-1989', 'YearBuilt_1990-1999', 'YearBuilt_2000-2009', 'YearBuilt_2010-2019', 'YearBuilt_2020-2029', 'Type_BUNGALOW', 'Type_COTTAGE', 'Type_DETACHED', 'Type_END OF TERRACE', 'Type_FLAT', 'Type_SEMI-DETACHED', 'Type_MID-TERRACE', 'Type_STUDENT HALLS', 'Type_FACTORY', 'Type_OFFICE', 'Type_UNIVERSITY', 'NumRooms', 'NumOccupants', 'Total', 'AlwaysOn', 'Intermit', 'HVAC']\n",
            "X.head----->>>>> ['HouseNum', 'TimeSin', 'TimeCos', 'DayNumSin', 'DayNumCos', 'MonthSin', 'MonthCos', 'RealTemp', 'ApparTemp', 'Humid', 'Wmo_0-9', 'Wmo_10-19', 'Wmo_20-29', 'Wmo_30-39', 'Wmo_40-49', 'Wmo_50-59', 'Wmo_60-69', 'Wmo_70-79', 'Wmo_80-89', 'Wmo_90-99', 'YearBuilt__under_1899', 'YearBuilt_1900-1909', 'YearBuilt_1910-1919', 'YearBuilt_1920-1929', 'YearBuilt_1930-1939', 'YearBuilt_1940-1949', 'YearBuilt_1950-1959', 'YearBuilt_1960-1969', 'YearBuilt_1970-1979', 'YearBuilt_1980-1989', 'YearBuilt_1990-1999', 'YearBuilt_2000-2009', 'YearBuilt_2010-2019', 'YearBuilt_2020-2029', 'Type_BUNGALOW', 'Type_COTTAGE', 'Type_DETACHED', 'Type_END OF TERRACE', 'Type_FLAT', 'Type_SEMI-DETACHED', 'Type_MID-TERRACE', 'Type_STUDENT HALLS', 'Type_FACTORY', 'Type_OFFICE', 'Type_UNIVERSITY', 'NumRooms', 'NumOccupants', 'Total']\n",
            "Y.head----->>>>> ['AlwaysOn', 'Intermit', 'HVAC']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# print(house_df.head())\n",
        "print(\"house_df---->>>>\",house_df.columns.to_list())\n",
        "# selected_features = ['AlwaysOn', 'Intermit', 'HVAC']\n",
        "\n",
        "X = house_df.iloc[:, :-3] # all the features for the training\n",
        "Y = house_df.iloc[:, -3:] # Last 3 are ['AlwaysOn', 'Intermit', 'HVAC']\n",
        "\n",
        "print(\"X.head----->>>>>\", X.columns.to_list())\n",
        "print(\"Y.head----->>>>>\",Y.columns.to_list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "35a13cce-2366-4c08-8fb2-2e4baba9e5fe",
      "metadata": {
        "id": "35a13cce-2366-4c08-8fb2-2e4baba9e5fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1363f95e-af57-4d15-f247-6d351af2ef85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original total energy test data, X_test:            Total\n",
            "4       4.791903\n",
            "6       3.172128\n",
            "12      4.472217\n",
            "22      5.796822\n",
            "24      5.150908\n",
            "...          ...\n",
            "220455  5.946285\n",
            "220456  5.946285\n",
            "220458  5.946285\n",
            "220462  5.946285\n",
            "220466  5.946285\n",
            "\n",
            "[44094 rows x 1 columns]\n",
            "total_energy_inverseYeoJohnson_df\n",
            "            Total\n",
            "4        305.909\n",
            "6         33.708\n",
            "12       193.716\n",
            "22      1407.225\n",
            "24       519.030\n",
            "...          ...\n",
            "220455  1789.000\n",
            "220456  1789.000\n",
            "220458  1789.000\n",
            "220462  1789.000\n",
            "220466  1789.000\n",
            "\n",
            "[44094 rows x 1 columns]\n",
            "total_energy_inverseYeoJohnson_df.shape (44094, 1)\n",
            "total_energy_inverseYeoJohnson :\n",
            "  4          305.909\n",
            "6           33.708\n",
            "12         193.716\n",
            "22        1407.225\n",
            "24         519.030\n",
            "            ...   \n",
            "220455    1789.000\n",
            "220456    1789.000\n",
            "220458    1789.000\n",
            "220462    1789.000\n",
            "220466    1789.000\n",
            "Length: 44094, dtype: float64\n",
            "y_test____\n",
            "         AlwaysOn  Intermit      HVAC\n",
            "4       0.296886  0.100860  0.602254\n",
            "6       0.055180  0.220333  0.724487\n",
            "12      0.187666  0.005162  0.807171\n",
            "22      0.048238  0.368817  0.582944\n",
            "24      0.142816  0.009791  0.847392\n",
            "...          ...       ...       ...\n",
            "220455  0.077697  0.045277  0.877026\n",
            "220456  0.077697  0.045277  0.877026\n",
            "220458  0.077697  0.045277  0.877026\n",
            "220462  0.077697  0.045277  0.877026\n",
            "220466  0.077697  0.045277  0.877026\n",
            "\n",
            "[44094 rows x 3 columns]\n",
            "y_test.shape (44094, 3)\n",
            "result: \n",
            "         AlwaysOn  Intermit      HVAC\n",
            "4         90.820    30.854   184.235\n",
            "6          1.860     7.427    24.421\n",
            "12        36.354     1.000   156.362\n",
            "22        67.882   519.009   820.334\n",
            "24        74.126     5.082   439.822\n",
            "...          ...       ...       ...\n",
            "220455   139.000    81.000  1569.000\n",
            "220456   139.000    81.000  1569.000\n",
            "220458   139.000    81.000  1569.000\n",
            "220462   139.000    81.000  1569.000\n",
            "220466   139.000    81.000  1569.000\n",
            "\n",
            "[44094 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming X is your feature matrix and Y is the target matrix with 3 columns\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "total_energy_test = pd.DataFrame(X_test['Total'])\n",
        "print(\"Original total energy test data, X_test:\", total_energy_test.sort_index())\n",
        "\n",
        "# Define the inverse Yeo-Johnson function\n",
        "def inverse_yeo_johnson(y, lambda_):\n",
        "    if lambda_ == 0:\n",
        "        return np.exp(y) - 1\n",
        "    else:\n",
        "        if y >= 0:\n",
        "            return (y * lambda_ + 1) ** (1 / lambda_) - 1\n",
        "        else:\n",
        "            return -((1 - y * (2 - lambda_)) ** (1 / (2 - lambda_)) - 1)\n",
        "\n",
        "\n",
        "lambda_value = -0.06419593996677918\n",
        "total_energy_inverseYeoJohnson = total_energy_test.apply(lambda row: inverse_yeo_johnson(row['Total'], lambda_value), axis=1)\n",
        "total_energy_inverseYeoJohnson_df = pd.DataFrame(total_energy_inverseYeoJohnson, columns=['Total'])\n",
        "print(\"total_energy_inverseYeoJohnson_df\\n\",total_energy_inverseYeoJohnson_df.sort_index())\n",
        "print(\"total_energy_inverseYeoJohnson_df.shape\", total_energy_inverseYeoJohnson_df.shape)\n",
        "\n",
        "print(\"total_energy_inverseYeoJohnson :\\n \",total_energy_inverseYeoJohnson.sort_index())\n",
        "print(\"y_test____\\n\",y_test.sort_index())\n",
        "print(\"y_test.shape\", y_test.shape)\n",
        "\n",
        "\n",
        "# Convert DataFrames to numpy arrays\n",
        "total_energy_inverseYeoJohnson_array = total_energy_inverseYeoJohnson_df.values\n",
        "y_test_array = y_test.values\n",
        "\n",
        "y_test_actuals = y_test_array * total_energy_inverseYeoJohnson_array\n",
        "y_test_actuals_df = pd.DataFrame(y_test_actuals, index=y_test.index, columns=y_test.columns)\n",
        "print(\"result: \\n\",y_test_actuals_df.sort_index())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance Analytics"
      ],
      "metadata": {
        "id": "Pt4iARtxVPJ_"
      },
      "id": "Pt4iARtxVPJ_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definitions:<br>\n",
        "**MSE**:<br>\n",
        "-> Definition: MSE measures the average of\n",
        "the squared differences between actual and predicted values. It is calculated by taking the average of the square of the errors (difference between actual and predicted values). <br>\n",
        "-> Usage: MSE is useful for evaluating the variance of the model's errors. Lower MSE values indicate better model performance\n",
        "<br>\n",
        "**RMSE**:<br>\n",
        "-> Definition: RMSE is the square root of the mean squared error. It measures the standard deviation of the residuals (errors).<br>\n",
        "-> Usage: RMSE is more interpretable than MSE because it is in the same units as the target variable. It provides insight into how close the model's predictions are to the actual values.\n",
        "<br>\n",
        "**MAE**:<br>\n",
        "-> Definition: MAE measures the average of the absolute differences between actual and predicted values. It is calculated by taking the mean of the absolute differences between actual and predicted values.<br>\n",
        "-> Usage: MAE is useful for measuring the average magnitude of errors, without considering their direction. Lower MAE values indicate better model performance.\n",
        "<br>\n",
        "**MAPE**:<br>\n",
        "-> Definition: MAPE measures the average of the absolute percentage differences between actual and predicted values. It expresses errors as percentages of actual values.<br>\n",
        "-> Usage: MAPE provides insight into the relative size of errors. It is useful for comparing model performance across different scales.\n",
        "<br>\n",
        "**R^2**:<br>\n",
        "-> Definition: R^2 measures the proportion of the variance in the target variable that is explained by the model. It ranges from 0 to 1, where 1 indicates a perfect fit.<br>\n",
        "-> Usage: R^2 provides a measure of how well the model explains the variability of the target variable. Higher values indicate better model performance."
      ],
      "metadata": {
        "id": "e9rA4f6-tBFq"
      },
      "id": "e9rA4f6-tBFq"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
        "import numpy as np\n",
        "def calculate_performance_metrics(y_test_actuals, y_pred_actuals_model):\n",
        "    # Calculate performance metrics\n",
        "    metrics = {}\n",
        "\n",
        "    metrics['mse'] = mean_squared_error(y_test_actuals, y_pred_actuals_model, multioutput='raw_values')\n",
        "    metrics['rmse'] = np.sqrt(metrics['mse'])\n",
        "    metrics['mae'] = mean_absolute_error(y_test_actuals, y_pred_actuals_model, multioutput='raw_values')\n",
        "    metrics['mape'] = mean_absolute_percentage_error(y_test_actuals, y_pred_actuals_model, multioutput='raw_values')\n",
        "    metrics['r2'] = r2_score(y_test_actuals, y_pred_actuals_model, multioutput='raw_values')\n",
        "\n",
        "\n",
        "    # Check if any of the predicted values are negative\n",
        "    negative_values = y_pred_actuals_model < 0\n",
        "    num_negative_values = np.sum(negative_values)\n",
        "    if num_negative_values > 0:\n",
        "        print(f\"Warning!!: {num_negative_values} predicted values are negative\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def print_performance_metrics(metrics):\n",
        "    print(\"Y.head: \",Y.columns.to_list())\n",
        "    print(\"MSE per output:\", metrics['mse'])\n",
        "    print(\"RMSE per output:\", metrics['rmse'])\n",
        "    print(\"MAE per output:\", metrics['mae'])\n",
        "    print(\"MAPE per output:\", metrics['mape'])\n",
        "    print(\"R^2 per output:\", metrics['r2'])\n",
        "\n"
      ],
      "metadata": {
        "id": "puE_g4N_nd60"
      },
      "id": "puE_g4N_nd60",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression"
      ],
      "metadata": {
        "id": "-qi9ZLVcsoQf"
      },
      "id": "-qi9ZLVcsoQf"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "e9a66868-e38e-4989-9afc-c30191e0def7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9a66868-e38e-4989-9afc-c30191e0def7",
        "outputId": "e53c52cb-21d6-4b3f-f896-39f5e19a9404"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        AlwaysOn  Intermit      HVAC\n",
            "162687  0.080576  0.089216  0.830208\n",
            "22801   0.190761  0.098911  0.710328\n",
            "203564  0.396688  0.030601  0.572711\n",
            "140524  0.000000  0.166675  0.833325\n",
            "129027  0.126301  0.595352  0.278347\n",
            "AlwaysOn    0\n",
            "Intermit    0\n",
            "HVAC        0\n",
            "dtype: int64\n",
            "y_pred_fracs_linear [[0.18243149 0.18373948 0.63382902]\n",
            " [0.18243149 0.18373948 0.63382902]\n",
            " [0.18243149 0.18373948 0.63382902]\n",
            " ...\n",
            " [0.18243149 0.18373948 0.63382902]\n",
            " [0.18243149 0.18373948 0.63382902]\n",
            " [0.18243149 0.18373948 0.63382902]]\n",
            "result:                  0           1           2\n",
            "0      113.542990  114.357066  394.486944\n",
            "1      131.349581  132.291326  456.353094\n",
            "2      122.128398  123.004030  424.315572\n",
            "3      121.128127  121.996586  420.840287\n",
            "4       15.342489   15.452491   53.305021\n",
            "...           ...         ...         ...\n",
            "44089   41.276402   41.572344  143.408253\n",
            "44090   25.677233   25.861332   89.211435\n",
            "44091  158.865358  160.004384  551.952258\n",
            "44092  109.892353  110.680255  381.803392\n",
            "44093   43.006400   43.314746  149.418854\n",
            "\n",
            "[44094 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Print the first five rows of y_train\n",
        "print(y_train.head())\n",
        "\n",
        "# Check for missing values in y_train\n",
        "print(y_train.isnull().sum())\n",
        "\n",
        "# Initialize and fit the model\n",
        "linear_model = MultiOutputRegressor(ElasticNet(random_state=42, positive=True)).fit(X_train, y_train)\n",
        "\n",
        "# Predicting the percentages\n",
        "y_pred_fracs_linear = linear_model.predict(X_test)\n",
        "print(\"y_pred_fracs_linear\", y_pred_fracs_linear)\n",
        "\n",
        "\n",
        "# Converting back to energy values\n",
        "y_pred_actuals_linear = y_pred_fracs_linear * total_energy_inverseYeoJohnson_array\n",
        "result_df = pd.DataFrame(y_pred_actuals_linear)\n",
        "print(\"result: \",result_df.sort_index())\n",
        "# performance analysis\n",
        "metrics = calculate_performance_metrics(y_test_actuals, y_pred_actuals_linear)\n",
        "print_performance_metrics(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graphs"
      ],
      "metadata": {
        "id": "Ha2H1HgasJuZ"
      },
      "id": "Ha2H1HgasJuZ"
    },
    {
      "cell_type": "code",
      "source": [
        "### residuals against predicted values###\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Calculate residuals\n",
        "residuals_linear = y_test_actuals - y_pred_actuals_linear\n",
        "\n",
        "\n",
        "# Plot residuals against predicted values\n",
        "for column in residuals_linear.columns:\n",
        "\n",
        "    # Extract the predicted values and residuals for the current target variable\n",
        "    current_predicted_values = y_pred_actuals_linear[:, residuals_linear.columns.get_loc(column)]\n",
        "    current_residuals = residuals_linear[column]\n",
        "\n",
        "    # Create a scatter plot of residuals vs. predicted values\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(current_predicted_values, current_residuals)\n",
        "    plt.axhline(0, color='red', linestyle='--')\n",
        "    plt.xlabel('Predicted Values')\n",
        "    plt.ylabel('Residuals')\n",
        "    plt.title(f'Residuals vs. Predicted Values (Linear Model) - {column}')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "tN2VQCp8CFif"
      },
      "id": "tN2VQCp8CFif",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###QQ plot###\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Calculate residuals\n",
        "residuals_linear = y_test_actuals - y_pred_actuals_linear\n",
        "\n",
        "# QQ plot of residuals\n",
        "# Loop through each column in the residuals\n",
        "for column in residuals_linear.columns:\n",
        "    # Extract the residuals for the current column\n",
        "    current_residuals = residuals_linear[column]\n",
        "\n",
        "    # Create a QQ plot for the current residuals\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    stats.probplot(current_residuals, dist=\"norm\", plot=plt)\n",
        "    plt.title(f'QQ Plot of Residuals (Linear Model) - {column}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "TtRcQviCqxzp"
      },
      "id": "TtRcQviCqxzp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.inspection import plot_partial_dependence\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # Features for which you want to plot PDPs\n",
        "# features_to_plot = ['Feature1', 'Feature2', 'Feature3']  # Replace with the features you want to visualize\n",
        "\n",
        "# # Output variables to visualize (index corresponds to the order of columns in y_train)\n",
        "# target_indices = [0, 1, 2]  # HVAC_frac, AlwaysOn_frac, Intermit_frac\n",
        "\n",
        "# # Create PDPs\n",
        "# fig, ax = plt.subplots(figsize=(10, 8))\n",
        "# plot_partial_dependence(\n",
        "#     estimator=linear_model,\n",
        "#     X=X_train,\n",
        "#     features=features_to_plot,\n",
        "#     target=target_indices,\n",
        "#     ax=ax,\n",
        "#     grid_resolution=50  # Number of points to use in grid\n",
        "# )\n",
        "\n",
        "# # Set titles for the plot\n",
        "# ax[0].set_title('HVAC_frac')\n",
        "# ax[1].set_title('AlwaysOn_frac')\n",
        "# ax[2].set_title('Intermit_frac')\n",
        "\n",
        "# # Show plot\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "V0ICKIFjkFiO"
      },
      "id": "V0ICKIFjkFiO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ###SHAP (Shapley Additive Explanations)###\n",
        "\n",
        "# import shap\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# # Initialize the SHAP explainer for your model\n",
        "# explainer = shap.Explainer(linear_model, X_train)\n",
        "\n",
        "# # Compute SHAP values for the test set\n",
        "# shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "# # Create SHAP summary plot for each target variable\n",
        "# for i, target in enumerate(['HVAC', 'AlwaysOn', 'Intermit']):\n",
        "#     # Use shap.summary_plot for each target variable\n",
        "#     shap.summary_plot(shap_values[i], X_test, feature_names=selected_features, show=False)\n",
        "#     plt.title(f'SHAP Summary Plot for {target}')\n",
        "#     plt.show()"
      ],
      "metadata": {
        "id": "5MUo52f1kOxx"
      },
      "id": "5MUo52f1kOxx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest Regressor"
      ],
      "metadata": {
        "id": "TfiD96KCrnC5"
      },
      "id": "TfiD96KCrnC5"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "abd00eae-954a-4941-a533-a206e3405b0c",
      "metadata": {
        "id": "abd00eae-954a-4941-a533-a206e3405b0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a2f7a1e-b6cc-4380-bf20-2d699f7386a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.5min finished\n",
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.5min finished\n",
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.5min finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.8s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    1.7s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.8s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    1.7s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE per output: [ 1248.94114297 15374.91660792 15620.75241501]\n",
            "RMSE per output: [ 35.34036139 123.99563141 124.98300851]\n",
            "MAE per output: [17.47298516 53.00004516 56.25743013]\n",
            "MAPE per output: [2.29175142e+15 6.52421968e+15 4.24229230e+12]\n",
            "R^2 per output: [0.63607953 0.80154806 0.90569194]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    1.6s finished\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Initialize and fit the model\n",
        "rf_model = MultiOutputRegressor(RandomForestRegressor(\n",
        "    verbose=1,\n",
        "    n_jobs=-1,\n",
        "    n_estimators=100, #try 50 # was 100\n",
        "    # max_depth = 10, #default is none\n",
        "    # max_features=0.5, # Fewer features per split, less memory\n",
        "    random_state=42\n",
        "))\n",
        "\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the fractions\n",
        "y_pred_fracs_rf = rf_model.predict(X_test)\n",
        "\n",
        "\n",
        "##########MODEL 2 batching#########################\n",
        "###### I dont think this works#######\n",
        "\n",
        "\n",
        "# from sklearn.ensemble import RandomForestRegressor\n",
        "# batch_size = 16  # make lower if crashing\n",
        "# #512 , 256, 64, 32, 16,8\n",
        "# forest_model = RandomForestRegressor(\n",
        "#     verbose=1,\n",
        "#     n_jobs=-1,\n",
        "#     n_estimators=16, #try 50 # was 100\n",
        "#     # max_depth = 10, #default is none\n",
        "#     # max_features=0.5, # Fewer features per split, less memory\n",
        "#     random_state=42\n",
        "# )\n",
        "\n",
        "# start_idx = 0\n",
        "# while start_idx < len(X_train):\n",
        "#     # Get the end index for the current batch\n",
        "#     end_idx = min(start_idx + batch_size, len(X_train))\n",
        "\n",
        "#     # Get the current batch of data\n",
        "#     X_batch = X_train[start_idx:end_idx]\n",
        "#     y_batch = y_train[start_idx:end_idx]\n",
        "\n",
        "#     # Fit the model on the current batch\n",
        "#     forest_model.fit(X_batch, y_batch)\n",
        "\n",
        "#     # Move to the next batch\n",
        "#     start_idx = end_idx\n",
        "\n",
        "\n",
        "# y_pred_fracs_forest = []\n",
        "# start_idx = 0\n",
        "# while start_idx < len(X_test):\n",
        "#     # Get the end index for the current batch\n",
        "#     end_idx = min(start_idx + batch_size, len(X_test))\n",
        "\n",
        "#     # Get the current batch of data\n",
        "#     X_test_batch = X_test[start_idx:end_idx]\n",
        "\n",
        "#     # Predict the fractions for the current batch\n",
        "#     y_pred_fracs_forest_batch = forest_model.predict(X_test_batch)\n",
        "\n",
        "#     # Append the predictions to the overall list\n",
        "#     y_pred_fracs_forest.extend(y_pred_fracs_forest_batch)\n",
        "\n",
        "#   # Move to the next batch\n",
        "#     start_idx = end_idx\n",
        "\n",
        "\n",
        "# Converting back to energy values\n",
        "y_pred_actuals_rf = y_pred_fracs_rf * total_energy_inverseYeoJohnson_array\n",
        "\n",
        "# calculate metrics\n",
        "metrics = calculate_performance_metrics(y_test_actuals, y_pred_actuals_rf)\n",
        "print_performance_metrics(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest Regressor GridSearchCV"
      ],
      "metadata": {
        "id": "z6wLHOJDvmX8"
      },
      "id": "z6wLHOJDvmX8"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "param_grid = {\n",
        "    'estimator__n_estimators': [50, 100],\n",
        "    'estimator__max_depth': [5, 10],\n",
        "    'estimator__min_samples_split': [2, 5],\n",
        "    'estimator__min_samples_leaf': [1, 2],\n",
        "    'estimator__max_features': ['sqrt'],\n",
        "}\n",
        "\n",
        "# param_grid = {\n",
        "#     'estimator__n_estimators': [100, 200, 300],\n",
        "#     'estimator__max_depth': [10, 20, 30],\n",
        "#     'estimator__min_samples_split': [5, 10, 15],\n",
        "#     'estimator__min_samples_leaf': [2, 4, 6],\n",
        "#     'estimator__max_features': ['sqrt', 'log2'],\n",
        "# }\n",
        "\n",
        "rf_model = MultiOutputRegressor(RandomForestRegressor(\n",
        "    verbose=1,\n",
        "    n_jobs=-1,\n",
        "    n_estimators=100, #try 50 # was 100\n",
        "    # max_depth = 10, #default is none\n",
        "    # max_features=0.5, # Fewer features per split, less memory\n",
        "    random_state=42\n",
        "))\n",
        "# rf_model = MultiOutputRegressor(RandomForestRegressor(random_state=42))\n",
        "\n",
        "\n",
        "grid_search_rf = GridSearchCV(\n",
        "    rf_model,\n",
        "    param_grid,\n",
        "    cv=3,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    n_jobs=-1)\n",
        "grid_search_rf.fit(X_train, y_train)\n",
        "best_rf_model = grid_search_rf.best_estimator_\n",
        "best_params_ = grid_search_rf.best_params_\n",
        "\n",
        "print(\"best_params_ ----> Random Forest:\", best_params_)\n",
        "print(\"best_rf_model: \", best_rf_model)\n",
        "y_pred_fracs_best_rf = best_rf_model.predict(X_test)\n",
        "\n",
        "\n",
        "# Converting back to energy values\n",
        "y_pred_actuals_rf = y_pred_fracs_rf * total_energy_inverseYeoJohnson_array\n",
        "# calculate metrics\n",
        "metrics = calculate_performance_metrics(y_test_actuals, y_pred_actuals_rf)\n",
        "print_performance_metrics(metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47bGN2K60BWp",
        "outputId": "9ed05510-34df-4786-99f7-d0a2c067a4e0"
      },
      "id": "47bGN2K60BWp",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_params_ ----> Random Forest: {'estimator__max_depth': 5, 'estimator__max_features': 'sqrt', 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'estimator__n_estimators': 100}\n",
            "best_rf_model:  MultiOutputRegressor(estimator=RandomForestRegressor(max_depth=5,\n",
            "                                                     max_features='sqrt',\n",
            "                                                     min_samples_leaf=2,\n",
            "                                                     random_state=42))\n",
            "MSE per output (best RF): [ 1136.66330419 50173.44688656 49124.72627347]\n",
            "RMSE per output (best RF): [ 33.71443762 223.99430101 221.64098509]\n",
            "MAE per output (best RF): [ 21.52670528 125.51942511 125.59487467]\n",
            "MAPE per output (best RF): [7.85907375e+01 1.52998168e+17 2.99874283e+01]\n",
            "R^2 per output (best RF): [0.0095653  0.72281203 0.73964588]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest Regressor RandomizedSearchCV"
      ],
      "metadata": {
        "id": "x1urNr9bvpwU"
      },
      "id": "x1urNr9bvpwU"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "param_dist_rf = {\n",
        "    'estimator__n_estimators': randint(50, 200),  # Number of trees in the forest\n",
        "    'estimator__max_depth': [None, 10, 20, 30, 40],  # Maximum depth of trees\n",
        "    'estimator__min_samples_split': randint(2, 10),  # Minimum samples for splitting a node\n",
        "    'estimator__min_samples_leaf': randint(1, 4),  # Minimum samples per leaf\n",
        "    # 'estimator__max_features': ['auto', 'sqrt', 'log2', 1.0],  # Number of features to consider for splitting\n",
        "    'estimator__max_features': [1.0],  # Number of features to consider for splitting\n",
        "}\n",
        "\n",
        "\n",
        "# Initialize and fit the model\n",
        "rf_model = MultiOutputRegressor(RandomForestRegressor(\n",
        "    verbose=1,\n",
        "    n_jobs=-1,\n",
        "    n_estimators=100, #try 50 # was 100\n",
        "    # max_depth = 10, #default is none\n",
        "    # max_features=0.5, # Fewer features per split, less memory\n",
        "    random_state=42\n",
        "))\n",
        "# rf_model = MultiOutputRegressor(RandomForestRegressor(random_state=42))\n",
        "\n",
        "\n",
        "randomized_search_rf = RandomizedSearchCV(\n",
        "    estimator=rf_model,\n",
        "    param_distributions=param_dist_rf,\n",
        "    n_iter=10,  # Number of random combinations to try\n",
        "    scoring='neg_mean_squared_error',  # Metric to optimize\n",
        "    # n_jobs=-1,\n",
        "    cv=3,  # Number of cross-validation folds\n",
        "    random_state=42  # For reproducibility\n",
        ")\n",
        "\n",
        "randomized_search_rf.fit(X_train, y_train)\n",
        "print(\"best_params_ ---> RandomForestRegressor:\", randomized_search_rf.best_params_)\n",
        "print(\"best_rf_model---> RandomForestRegressor:\", randomized_search_rf.best_rf_model)\n",
        "\n",
        "\n",
        "# Converting back to energy values\n",
        "y_pred_actuals_rf = y_pred_fracs_rf * total_energy_inverseYeoJohnson_array\n",
        "\n",
        "# calculate metrics\n",
        "metrics = calculate_performance_metrics(y_test_actuals, y_pred_actuals_rf)\n",
        "print_performance_metrics(metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "fOZ-D_feZJpq",
        "outputId": "bca1defb-4c24-43d0-8661-ff76f7274060"
      },
      "id": "fOZ-D_feZJpq",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-0410ff654f0a>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mrandomized_search_rf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best_params_ ---> RandomForestRegressor:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomized_search_rf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best_rf_model---> RandomForestRegressor: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomized_search_rf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_rf_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m         evaluate_candidates(\n\u001b[0m\u001b[1;32m   1769\u001b[0m             ParameterSampler(\n\u001b[1;32m   1770\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/multioutput.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mfit_params_validated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m    217\u001b[0m             delayed(_fit_estimator)(\n\u001b[1;32m    218\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_validated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/multioutput.py\u001b[0m in \u001b[0;36m_fit_estimator\u001b[0;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \"\"\"\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    377\u001b[0m             )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Boosting"
      ],
      "metadata": {
        "id": "pCkRlwOgr295"
      },
      "id": "pCkRlwOgr295"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "46af6598-7d18-4f15-92c5-fe0d739f5a94",
      "metadata": {
        "id": "46af6598-7d18-4f15-92c5-fe0d739f5a94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb4f6317-3e48-44fd-d56b-a2a0e320a6f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result:                  0           1           2\n",
            "0       53.920039  170.678061  379.050319\n",
            "1       72.909537  220.926222  451.484971\n",
            "2      110.571738  122.543179  416.299081\n",
            "3       73.932349  269.415893  385.676777\n",
            "4        0.261486    8.729433   71.264160\n",
            "...           ...         ...         ...\n",
            "44089   48.799087   20.551639  146.825160\n",
            "44090   35.700358    5.922294   97.266478\n",
            "44091   33.582263  121.902000  686.724284\n",
            "44092   56.536256   74.547774  451.013466\n",
            "44093   29.436073   23.061281  187.198236\n",
            "\n",
            "[44094 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "boost_model = MultiOutputRegressor(XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)).fit(X_train, y_train)\n",
        "\n",
        "# Predict the fractions\n",
        "y_pred_fracs_gb = boost_model.predict(X_test)\n",
        "\n",
        "# Converting back to energy values\n",
        "y_pred_fracs_gb = y_pred_fracs_rf * total_energy_inverseYeoJohnson_array\n",
        "# calculate metrics\n",
        "metrics = calculate_performance_metrics(y_test_actuals, y_pred_fracs_gb)\n",
        "print_performance_metrics(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Boosting GridSearchCV"
      ],
      "metadata": {
        "id": "Uqqf1e5DvOWv"
      },
      "id": "Uqqf1e5DvOWv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9fa5482-1c50-4481-b4dd-26118290311a",
      "metadata": {
        "id": "b9fa5482-1c50-4481-b4dd-26118290311a"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid_gb = {\n",
        "    'estimator__n_estimators': [50, 100],\n",
        "    'estimator__max_depth': [3, 6, 9],\n",
        "    'estimator__learning_rate': [0.1, 0.01],\n",
        "    'estimator__subsample': [0.8, 1.0],\n",
        "}\n",
        "\n",
        "# Initialize the MultiOutputRegressor with XGBRegressor\n",
        "gb_model = MultiOutputRegressor(XGBRegressor(objective='reg:squarederror', random_state=42))\n",
        "\n",
        "# Grid search\n",
        "grid_search_gb = GridSearchCV(\n",
        "    estimator=gb_model,\n",
        "    param_grid=param_grid_gb,\n",
        "    cv=3,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    n_jobs=-1\n",
        ")\n",
        "grid_search_gb.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model and its parameters\n",
        "best_gb_model = grid_search_gb.best_estimator_\n",
        "best_params_gb = grid_search_gb.best_params_\n",
        "\n",
        "print(\"best_params_ ----> Gradient Boosting:\", best_params_gb)\n",
        "print(\"best_gb_model: \", best_gb_model)\n",
        "\n",
        "# Predict using the best model\n",
        "y_pred_fracs_gb = best_gb_model.predict(X_test)\n",
        "\n",
        "# Converting back to energy values\n",
        "y_pred_actuals_gb = y_pred_fracs_gb * total_energy_inverseYeoJohnson_array\n",
        "\n",
        "# calculate metrics\n",
        "metrics = calculate_performance_metrics(y_test_actuals, y_pred_actuals_gb)\n",
        "print_performance_metrics(metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Boosting RandomizedSearchCV"
      ],
      "metadata": {
        "id": "aWQMnh0VvYif"
      },
      "id": "aWQMnh0VvYif"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint, uniform\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Define the parameter distributions\n",
        "param_dist_gb = {\n",
        "    'estimator__n_estimators': randint(50, 200),\n",
        "    'estimator__max_depth': [3, 6, 9, None],\n",
        "    'estimator__learning_rate': uniform(0.01, 0.1),\n",
        "    'estimator__subsample': uniform(0.5, 0.5),\n",
        "}\n",
        "\n",
        "# Initialize the MultiOutputRegressor with XGBRegressor\n",
        "gb_model = MultiOutputRegressor(XGBRegressor(objective='reg:squarederror', random_state=42))\n",
        "\n",
        "# Randomized search\n",
        "randomized_search_gb = RandomizedSearchCV(\n",
        "    estimator=gb_model,\n",
        "    param_distributions=param_dist_gb,\n",
        "    n_iter=10,\n",
        "    cv=3,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    random_state=42\n",
        ")\n",
        "randomized_search_gb.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model and its parameters\n",
        "best_gb_model = randomized_search_gb.best_estimator_\n",
        "best_params_gb = randomized_search_gb.best_params_\n",
        "\n",
        "print(\"best_params_ ----> Gradient Boosting:\", best_params_gb)\n",
        "print(\"best_gb_model: \", best_gb_model)\n",
        "\n",
        "# Predict using the best model\n",
        "y_pred_fracs_gb = best_gb_model.predict(X_test)\n",
        "\n",
        "# Converting back to energy values\n",
        "y_pred_actuals_gb = y_pred_fracs_gb * total_energy_inverseYeoJohnson_array\n",
        "\n",
        "# calculate metrics\n",
        "metrics = calculate_performance_metrics(y_test_actuals, y_pred_actuals_gb)\n",
        "print_performance_metrics(metrics)\n"
      ],
      "metadata": {
        "id": "FgSOAr1svbLc"
      },
      "id": "FgSOAr1svbLc",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}