{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11f4be37-50cb-4884-98d0-5433aff0db10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read in the csv\n",
    "house_path = 'C:\\\\Users\\\\nicho\\\\OneDrive - The University of Western Ontario\\\\Ecolux\\\\Databases\\\\REFIT\\\\Regression Training Set\\\\house5.csv'\n",
    "house_df = pd.read_csv(house_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "747e7d38-e72d-4a62-aa72-c350808f728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the time to int with error handling\n",
    "def convert_time_to_seconds(time_str):\n",
    "    try:\n",
    "        hours, minutes, seconds = [int(part) for part in time_str.split(':')]\n",
    "        return hours * 3600 + minutes * 60 + seconds\n",
    "    except ValueError:\n",
    "        return 0\n",
    "\n",
    "house_df['Time'] = house_df['Time'].apply(convert_time_to_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "866fabb2-03e7-4a8b-af53-d7f94a991443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the x and y inputs\n",
    "house_df.drop(house_df.iloc[:, 0:1], inplace=True, axis=1)\n",
    "# selected_features = ['HVAC', 'AlwaysOn', 'Intermit','TimeSin', 'TimeCos', 'DayNumSin', 'DayNumCos', 'MonthSin', 'MonthCos', 'RealTemp', 'ApparTemp', 'Humid']\n",
    "X = house_df.drop(columns=['HVAC', 'AlwaysOn', 'Intermit'])\n",
    " # ['HVAC', 'AlwaysOn', 'Intermit','TimeSin', 'TimeCos', 'DayNumSin', 'DayNumCos', 'MonthSin', 'MonthCos', 'RealTemp', 'ApparTemp', 'Humid']\n",
    " #we also need the house number\n",
    "y = house_df[['HVAC', 'AlwaysOn', 'Intermit']].copy()\n",
    "\n",
    "# Determining sums\n",
    "total_energy = X['Total']\n",
    "y['HVAC_frac'] = y['HVAC'] / total_energy\n",
    "y['AlwaysOn_frac'] = y['AlwaysOn'] / total_energy\n",
    "y['Intermit_frac'] = y['Intermit'] / total_energy\n",
    "\n",
    "# New y with fractions\n",
    "y_frac = y[['AlwaysOn_frac', 'Intermit_frac', 'HVAC_frac']]\n",
    "print(y_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35a13cce-2366-4c08-8fb2-2e4baba9e5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Assuming X is your feature matrix and y is the target matrix with 3 columns\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_frac, test_size=0.2, random_state=42)\n",
    "\n",
    "# y testing data for usage amounts\n",
    "total_energy_test = np.array(X_test['Total'])\n",
    "# total_energy_test = X_test['Total']\n",
    "y_test_actuals = y_test * total_energy_test[:, None]\n",
    "y_test_actuals_df = pd.DataFrame(y_test_actuals, columns=y_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9a66868-e38e-4989-9afc-c30191e0def7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Print the first five rows of y_train\n",
    "print(y_train.head())\n",
    "\n",
    "# Check for missing values in y_train\n",
    "print(y_train.isnull().sum())\n",
    "\n",
    "# Initialize and fit the model\n",
    "linear_model = MultiOutputRegressor(ElasticNet(random_state=42, positive=True)).fit(X_train, y_train)\n",
    "\n",
    "# Predicting the percentages\n",
    "y_pred_fracs_linear = linear_model.predict(X_test)\n",
    "\n",
    "# Converting back to energy values\n",
    "y_pred_actuals_linear = y_pred_fracs_linear * total_energy_test[:, None]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5016d57",
   "metadata": {},
   "source": [
    "# Definitions:\n",
    "**MSE**:<br>\n",
    "-> Definition: MSE measures the average of\n",
    "the squared differences between actual and predicted values. It is calculated by taking the average of the square of the errors (difference between actual and predicted values). <br>\n",
    "-> Usage: MSE is useful for evaluating the variance of the model's errors. Lower MSE values indicate better model performance\n",
    "<br>\n",
    "**RMSE**:<br>\n",
    "-> Definition: RMSE is the square root of the mean squared error. It measures the standard deviation of the residuals (errors).<br>\n",
    "-> Usage: RMSE is more interpretable than MSE because it is in the same units as the target variable. It provides insight into how close the model's predictions are to the actual values.\n",
    "<br>\n",
    "**MAE**:<br>\n",
    "-> Definition: MAE measures the average of the absolute differences between actual and predicted values. It is calculated by taking the mean of the absolute differences between actual and predicted values.<br>\n",
    "-> Usage: MAE is useful for measuring the average magnitude of errors, without considering their direction. Lower MAE values indicate better model performance.\n",
    "<br>\n",
    "**MAPE**:<br>\n",
    "-> Definition: MAPE measures the average of the absolute percentage differences between actual and predicted values. It expresses errors as percentages of actual values.<br>\n",
    "-> Usage: MAPE provides insight into the relative size of errors. It is useful for comparing model performance across different scales.\n",
    "<br>\n",
    "**R^2**:<br>\n",
    "-> Definition: R^2 measures the proportion of the variance in the target variable that is explained by the model. It ranges from 0 to 1, where 1 indicates a perfect fit.<br>\n",
    "-> Usage: R^2 provides a measure of how well the model explains the variability of the target variable. Higher values indicate better model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "384a7eb4-1383-4f3c-8e67-412f4834ff63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE per output: [ 10682.51675107 212137.97634034 141786.21964131]\n",
      "R^2 per output: [-8.3082404  -0.17197638  0.24855303]\n"
     ]
    }
   ],
   "source": [
    "# Calculate performance metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "\n",
    "mse = mean_squared_error(y_test_actuals, y_pred_actuals_linear, multioutput='raw_values')\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test_actuals, y_pred_actuals_linear, multioutput='raw_values')\n",
    "mape = mean_absolute_percentage_error(y_test_actuals, y_pred_actuals_linear, multioutput='raw_values')\n",
    "mape_percentage = mape * 100\n",
    "r2 = r2_score(y_test_actuals, y_pred_actuals_linear, multioutput='raw_values')\n",
    "\n",
    "\n",
    "#when reding the data [0,1,2] The format is [HVAC_frac, AlwaysOn_frac, Intermit_frac] - but are converted back to the value\n",
    "print(\"MSE per output:\", mse)\n",
    "print(\"RMSE per output:\", rmse)\n",
    "print(\"MAE per output:\", mae)\n",
    "print(\"MAPE per output:\", mape_percentage)#check if this is right\n",
    "print(\"R^2 per output:\", r2)\n",
    "\n",
    "# Check if any of the predicted values are negative\n",
    "negative_values = y_pred_actuals_linear < 0\n",
    "num_negative_values = np.sum(negative_values)\n",
    "if num_negative_values > 0:\n",
    "    print(f\"Warning: {num_negative_values} predicted values are negative. Das is baaaad\")\n",
    "else:\n",
    "    print(\"No negative predicted values found. Das is go0o0o0od\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f4a911",
   "metadata": {},
   "outputs": [],
   "source": [
    "### residuals against predicted values###\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Calculate residuals\n",
    "residuals_linear = y_test_actuals - y_pred_actuals_linear\n",
    "\n",
    "\n",
    "# Plot residuals against predicted values\n",
    "for column in residuals_linear.columns:\n",
    "\n",
    "    # Extract the predicted values and residuals for the current target variable\n",
    "    current_predicted_values = y_pred_actuals_linear[:, residuals_linear.columns.get_loc(column)]\n",
    "    current_residuals = residuals_linear[column]\n",
    "\n",
    "    # Create a scatter plot of residuals vs. predicted values\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(current_predicted_values, current_residuals)\n",
    "    plt.axhline(0, color='red', linestyle='--')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.title(f'Residuals vs. Predicted Values (Linear Model) - {column}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94e46a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###QQ plot###\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "# Calculate residuals\n",
    "residuals_linear = y_test_actuals - y_pred_actuals_linear\n",
    "\n",
    "\n",
    "# QQ plot of residuals\n",
    "# Loop through each column in the residuals\n",
    "for column in residuals_linear.columns:\n",
    "    # Extract the residuals for the current column\n",
    "    current_residuals = residuals_linear[column]\n",
    "\n",
    "    # Create a QQ plot for the current residuals\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    stats.probplot(current_residuals, dist=\"norm\", plot=plt)\n",
    "    plt.title(f'QQ Plot of Residuals (Linear Model) - {column}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18435567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.inspection import plot_partial_dependence\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Features for which you want to plot PDPs\n",
    "# features_to_plot = ['Feature1', 'Feature2', 'Feature3']  # Replace with the features you want to visualize\n",
    "\n",
    "# # Output variables to visualize (index corresponds to the order of columns in y_train)\n",
    "# target_indices = [0, 1, 2]  # HVAC_frac, AlwaysOn_frac, Intermit_frac\n",
    "\n",
    "# # Create PDPs\n",
    "# fig, ax = plt.subplots(figsize=(10, 8))\n",
    "# plot_partial_dependence(\n",
    "#     estimator=linear_model,\n",
    "#     X=X_train,\n",
    "#     features=features_to_plot,\n",
    "#     target=target_indices,\n",
    "#     ax=ax,\n",
    "#     grid_resolution=50  # Number of points to use in grid\n",
    "# )\n",
    "\n",
    "# # Set titles for the plot\n",
    "# ax[0].set_title('HVAC_frac')\n",
    "# ax[1].set_title('AlwaysOn_frac')\n",
    "# ax[2].set_title('Intermit_frac')\n",
    "\n",
    "# # Show plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1140b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###SHAP (Shapley Additive Explanations)###\n",
    "\n",
    "# import shap\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# # Initialize the SHAP explainer for your model\n",
    "# explainer = shap.Explainer(linear_model, X_train)\n",
    "\n",
    "# # Compute SHAP values for the test set\n",
    "# shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# # Create SHAP summary plot for each target variable\n",
    "# for i, target in enumerate(['HVAC', 'AlwaysOn', 'Intermit']):\n",
    "#     # Use shap.summary_plot for each target variable\n",
    "#     shap.summary_plot(shap_values[i], X_test, feature_names=selected_features, show=False)\n",
    "#     plt.title(f'SHAP Summary Plot for {target}')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd00eae-954a-4941-a533-a206e3405b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I'm going to try random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "forest_model = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42)).fit(X_train, y_train)\n",
    "\n",
    "# Predict the fractions\n",
    "y_pred_fracs_forest = forest_model.predict(X_test)\n",
    "\n",
    "# Convert predictions back to energy values, as before\n",
    "y_pred_actuals_forest = y_pred_fracs_forest * total_energy_test[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f64d73e-d77d-4132-af1e-d91f7bffe2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(y_test_actuals, y_pred_actuals_forest, multioutput='raw_values')\n",
    "r2 = r2_score(y_test_actuals, y_pred_actuals_forest, multioutput='raw_values')\n",
    "\n",
    "print(\"MSE per output:\", mse)\n",
    "print(\"R^2 per output:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46af6598-7d18-4f15-92c5-fe0d739f5a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I'm going to try gradient boosting\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "boost_model = MultiOutputRegressor(XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)).fit(X_train, y_train)\n",
    "\n",
    "# Predict the fractions\n",
    "y_pred_fracs_boost = boost_model.predict(X_test)\n",
    "\n",
    "# Convert predictions back to energy values, as before\n",
    "y_pred_actuals_boost = y_pred_fracs_boost * total_energy_test[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33760e2b-03ad-4dfc-bd87-9651230a4fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE per output: [33623.66344407   994.7341691  33044.27320436]\n",
      "R^2 per output: [0.82179932 0.13323564 0.81744378]\n"
     ]
    }
   ],
   "source": [
    "# Calculate performance metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(y_test_actuals, y_pred_actuals_boost, multioutput='raw_values')\n",
    "r2 = r2_score(y_test_actuals, y_pred_actuals_boost, multioutput='raw_values')\n",
    "\n",
    "print(\"MSE per output:\", mse)\n",
    "print(\"R^2 per output:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fa5482-1c50-4481-b4dd-26118290311a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
